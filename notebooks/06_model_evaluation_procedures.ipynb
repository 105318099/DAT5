{
 "metadata": {
  "name": "",
  "signature": "sha256:f9765b574540deffd4f7e93a6a15a0aece0f76d9c6ebee098c34ae512a4573cf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Model Evaluation Procedures"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Motivating question:** Last time, we created classification models on the iris data to predict species using the iris measurements. We used KNN, with K=1 and K=5. But which model is \"better\"? And more importantly, what's the \"best\" value of K?\n",
      "\n",
      "To choose between models, we need two things: an \"evaluation procedure\" and an \"evaluation metric\":\n",
      "\n",
      "- The evaluation procedure is the process you use to evaluate a model.\n",
      "- The evaluation metric is the numeric calculation you use to compare models.\n",
      "\n",
      "In supervised learning, we define the \"best\" model as one that generalizes to \"out-of-sample\" data. In other words, we want a model that accurately predicts the future, not the past. Our evaluation procedure should support that goal. We will focus on evaluation procedures in  today's class.\n",
      "\n",
      "Choosing an evaluation metric is a more subjective decision. The appropriate evaluation metric can depend upon the goal of your problem. We will focus on evaluation metrics in a future class."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Option #1: Train and Test on Entire Dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's start by training on the entire iris dataset, and then testing our model by seeing how well it performs on that same data. That will be our evaluation procedure.\n",
      "\n",
      "We'll use **classification accuracy** as our evalutaion metric, which is the percentage of correct predictions. This is called a \"reward function\" because it's something we want to maximize.\n",
      "\n",
      "The opposite of classification accuracy is **classification error**, which is the percentage of incorrect predictions. This is called a \"loss function\" because it's something we want to minimize."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read in the iris data\n",
      "from sklearn.datasets import load_iris\n",
      "iris = load_iris()\n",
      "\n",
      "# create X (features) and y (response)\n",
      "X = iris.data\n",
      "y = iris.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# KNN with K=5\n",
      "from sklearn.neighbors import KNeighborsClassifier  # import class\n",
      "knn = KNeighborsClassifier(n_neighbors=5)           # instantiate the estimator\n",
      "knn.fit(X, y)                                       # train on entire dataset\n",
      "y_preds = knn.predict(X)                            # make predictions (or \"test\") on entire dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's now compute the accuracy. This is known as \"training accuracy\" because we are testing on the \"training data\"."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# method 1: use metrics module\n",
      "from sklearn import metrics\n",
      "print metrics.accuracy_score(y, y_preds)\n",
      "\n",
      "# method 2: use NumPy\n",
      "import numpy as np\n",
      "print np.mean(y == y_preds)\n",
      "\n",
      "# method 3: use built-in \"score\" method (you can skip the knn.predict step)\n",
      "print knn.score(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.966666666667\n",
        "0.966666666667\n",
        "0.966666666667\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I recommend method 1 because this pattern can be reused for various evaluation metrics."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compare to KNN with K=1\n",
      "knn = KNeighborsClassifier(n_neighbors=1)\n",
      "knn.fit(X, y)\n",
      "y_preds = knn.predict(X)\n",
      "print metrics.accuracy_score(y, y_preds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's amazing! So, K=1 is the best value for K, right?\n",
      "\n",
      "Not so fast...\n",
      "\n",
      "Training accuracy rewards overly complex models that do not generalize to out-of-sample data. Setting K=1 caused KNN to effectively memorize the training data. Thus, it will do very well when tested using the in-sample data, but may do very poorly on out-of-sample data. **As such, training accuracy is not a good estimate of out-of-sample accuracy.**\n",
      "\n",
      "Creating an unnecessarily complex model is known as **overfitting**, because our model is learning the \"noise\" rather than the \"signal\".\n",
      "\n",
      "From Quora: [What is an intuitive explanation of overfitting?](http://www.quora.com/What-is-an-intuitive-explanation-of-overfitting/answer/Jessica-Su)\n",
      "\n",
      "### Overfitting\n",
      "\n",
      "![Overfitting](06_overfitting.png)\n",
      "\n",
      "### Underfitting vs. Overfitting\n",
      "\n",
      "![Underfitting vs. Overfitting](06_underfitting_overfitting.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Option #2: Train/Test Split"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's now try an alternative model evaluation procedure known as \"train/test split\". (This is also known as the \"test set approach\" or the \"validation set approach\".) Here's our plan:\n",
      "\n",
      "1. Split the dataset into two pieces: a \"training set\" and a \"testing set\".\n",
      "2. Train the model on the training set.\n",
      "3. Test the model on the testing set, and evaluate how well we did.\n",
      "4. Repeat steps 2 and 3 with different tuning parameters (the value of K, in this case).\n",
      "\n",
      "Before we use this procedure, we first have to understand how the `train_test_split` function in scikit-learn works."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Understanding the `train_test_split` function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create X: 5 observations and 2 features\n",
      "X = np.arange(1, 11).reshape((5, 2))\n",
      "print X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1  2]\n",
        " [ 3  4]\n",
        " [ 5  6]\n",
        " [ 7  8]\n",
        " [ 9 10]]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# randomly split the rows of X into two pieces\n",
      "from sklearn.cross_validation import train_test_split\n",
      "X_train_test = train_test_split(X)\n",
      "print type(X_train_test)\n",
      "print X_train_test[0]\n",
      "print X_train_test[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'list'>\n",
        "[[5 6]\n",
        " [7 8]\n",
        " [3 4]]\n",
        "[[ 9 10]\n",
        " [ 1  2]]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use random_state argument to always get the same random split\n",
      "X_train_test = train_test_split(X, random_state=2)\n",
      "print X_train_test[0]\n",
      "print X_train_test[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[3 4]\n",
        " [7 8]\n",
        " [1 2]]\n",
        "[[ 5  6]\n",
        " [ 9 10]]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \"unpack\" the list into two separate objects\n",
      "X_train, X_test = train_test_split(X, random_state=2)\n",
      "print X_train\n",
      "print X_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[3 4]\n",
        " [7 8]\n",
        " [1 2]]\n",
        "[[ 5  6]\n",
        " [ 9 10]]\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create y: response vector of size 5\n",
      "y = X.prod(axis=1)\n",
      "print X\n",
      "print y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1  2]\n",
        " [ 3  4]\n",
        " [ 5  6]\n",
        " [ 7  8]\n",
        " [ 9 10]]\n",
        "[ 2 12 30 56 90]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# randomly split the rows of X and y into two pieces each\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# X has been split into two pieces\n",
      "print X_train\n",
      "print X_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[3 4]\n",
        " [7 8]\n",
        " [1 2]]\n",
        "[[ 5  6]\n",
        " [ 9 10]]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# y has been split into two pieces with the same ordering\n",
      "print y_train\n",
      "print y_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[12 56  2]\n",
        "[30 90]\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Using Train/Test Split on iris"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Step 0: load the iris data again\n",
      "iris = load_iris()\n",
      "X = iris.data\n",
      "y = iris.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Step 1: split data into a training set and a testing set\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=4)\n",
      "print X_train.shape\n",
      "print X_test.shape\n",
      "print y_train.shape\n",
      "print y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(112L, 4L)\n",
        "(38L, 4L)\n",
        "(112L,)\n",
        "(38L,)\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Step 2: train the model on the training set (using K=1)\n",
      "knn = KNeighborsClassifier(n_neighbors=1)\n",
      "knn.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_neighbors=1, p=2, weights='uniform')"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Step 3: test the model on the testing set, and check the accuracy\n",
      "y_preds = knn.predict(X_test)\n",
      "print metrics.accuracy_score(y_test, y_preds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.947368421053\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Step 4: repeat this process for K=5\n",
      "knn = KNeighborsClassifier(n_neighbors=5)\n",
      "knn.fit(X_train, y_train)\n",
      "y_preds = knn.predict(X_test)\n",
      "print metrics.accuracy_score(y_test, y_preds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.973684210526\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's assume we tried many values of K, and K=5 turned out to have the highest accuracy. Thus, we would declare K=5 to be the best parameter for K when using KNN on the iris dataset. We would also estimate that when given the measurements of an unknown iris, we would be able to correctly predict its species 97% of the time."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Making Predictions on Out-of-Sample Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are given the measurements of an unknown iris, and are asked to predict its species. How do we do it?\n",
      "\n",
      "1. We re-train our model on the **entire dataset**, using the best value for K found in the previous step.\n",
      "2. We make our prediction, and are 97% sure that we will make the correct prediction.\n",
      "\n",
      "It is important to re-train your model on all of the data, otherwise you will be ignoring valuable training data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train my KNN model on X (not X_train) using K=5\n",
      "knn = KNeighborsClassifier(n_neighbors=5)\n",
      "knn.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_neighbors=5, p=2, weights='uniform')"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make a prediction for an unknown iris\n",
      "out_of_sample = [5, 4, 3, 2]\n",
      "knn.predict(out_of_sample)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "array([1])"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## What's Wrong with Train/Test Split?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hypothetical question: What would happen if the `train_test_split` function had split the data differently? Would we get the same exact results as before?\n",
      "\n",
      "Let's check!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use a different random_state than last time\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
      "knn = KNeighborsClassifier(n_neighbors=5)\n",
      "knn.fit(X_train, y_train)\n",
      "y_preds = knn.predict(X_test)\n",
      "print metrics.accuracy_score(y_test, y_preds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It turns out that test set error is a \"high variance\" estimate of out-of-sample accuracy. We will learn an alternative model evaluation procedure called \"K-fold cross-validation\" in a future class that will provide a more accurate estimate of out-of-sample accuracy, and thus will be a better procedure for choosing the \"best\" model.\n",
      "\n",
      "Note that train/test split is still a very useful evaluation procedure because of its flexibility and speed, and thus we will use it throughout the course."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}